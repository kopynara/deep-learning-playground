{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00754e63",
   "metadata": {},
   "source": [
    "# ANN 04: ANN 모델 빌드 심화\n",
    "\n",
    "이번 챕터에서는 ANN 모델을 더 깊이 있게 빌드하는 방법을 배웁니다.\n",
    "\n",
    "📌 목표:\n",
    "- 활성화 함수 비교 (ReLU, Sigmoid, Tanh)\n",
    "- 옵티마이저 비교 (Adam, SGD, RMSprop)\n",
    "- 드롭아웃(Dropout)으로 과적합 방지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b96127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 18:28:49.303337: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-01 18:28:49.389797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-01 18:28:51.395835: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 준비 완료: (60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 한글 폰트 설정\n",
    "if platform.system() == 'Linux':\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "elif platform.system() == 'Darwin':\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"✅ 데이터 준비 완료:\", x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd65d79",
   "metadata": {},
   "source": [
    "## 🔑 활성화 함수 비교\n",
    "- ReLU: 가장 많이 쓰이는 기본값\n",
    "- Sigmoid: 출력이 0~1, 하지만 깊은 층에서는 기울기 소실 문제 발생\n",
    "- Tanh: -1~1 범위, Sigmoid보다 나음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86995fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccd/dl/v_dl/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-09-01 18:28:52.948307: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid 모델 정확도: 0.8670\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation=\"sigmoid\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer=\"adam\",\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "history_sigmoid = model_sigmoid.fit(x_train, y_train,\n",
    "                                    epochs=5,\n",
    "                                    validation_split=0.1,\n",
    "                                    batch_size=32,\n",
    "                                    verbose=0)\n",
    "\n",
    "acc_sigmoid = model_sigmoid.evaluate(x_test, y_test, verbose=0)[1]\n",
    "print(f\"Sigmoid 모델 정확도: {acc_sigmoid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a65922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanh 모델 정확도: 0.8732\n"
     ]
    }
   ],
   "source": [
    "model_tanh = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation=\"tanh\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_tanh.compile(optimizer=\"adam\",\n",
    "                   loss=\"sparse_categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "history_tanh = model_tanh.fit(x_train, y_train,\n",
    "                              epochs=5,\n",
    "                              validation_split=0.1,\n",
    "                              batch_size=32,\n",
    "                              verbose=0)\n",
    "\n",
    "acc_tanh = model_tanh.evaluate(x_test, y_test, verbose=0)[1]\n",
    "print(f\"Tanh 모델 정확도: {acc_tanh:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8715d",
   "metadata": {},
   "source": [
    "## ⚡ 옵티마이저 비교\n",
    "- Adam: 적응형 학습률, 대부분 기본값\n",
    "- SGD: 확률적 경사하강법, 단순하지만 속도 느림\n",
    "- RMSprop: 순환 신경망(RNN)에서 자주 쓰임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b333cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adam': 0.8711000084877014,\n",
       " 'sgd': 0.8381999731063843,\n",
       " 'rmsprop': 0.873199999332428}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers = [\"adam\", \"sgd\", \"rmsprop\"]\n",
    "results = {}\n",
    "\n",
    "for opt in optimizers:\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, epochs=5,\n",
    "              validation_split=0.1, batch_size=32, verbose=0)\n",
    "    acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "    results[opt] = acc\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b141f04",
   "metadata": {},
   "source": [
    "## 🛡️ Dropout 적용\n",
    "- 학습 중 무작위로 뉴런을 꺼서 과적합 방지\n",
    "- 일반적으로 0.2~0.5 사이 값 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b437e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout 모델 정확도: 0.8741\n"
     ]
    }
   ],
   "source": [
    "model_dropout = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_dropout.compile(optimizer=\"adam\",\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "history_dropout = model_dropout.fit(x_train, y_train,\n",
    "                                    epochs=10,\n",
    "                                    validation_split=0.1,\n",
    "                                    batch_size=32,\n",
    "                                    verbose=0)\n",
    "\n",
    "acc_dropout = model_dropout.evaluate(x_test, y_test, verbose=0)[1]\n",
    "print(f\"Dropout 모델 정확도: {acc_dropout:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5baad08",
   "metadata": {},
   "source": [
    "## ✅ 정리\n",
    "- 활성화 함수: ReLU > Tanh > Sigmoid\n",
    "- 옵티마이저: Adam이 가장 안정적\n",
    "- Dropout: 과적합 방지에 효과적\n",
    "\n",
    "👉 다음 챕터: **ANN을 활용한 Fashion-MNIST 실제 분류 프로젝트**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_dl (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
