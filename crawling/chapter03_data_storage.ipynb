{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85039a3",
   "metadata": {},
   "source": [
    "# Chapter 03: Data Storage\n",
    "📌 목표: 크롤링한 데이터를 파일(CSV/JSON)로 저장하고 불러온다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3277eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보통은 chapter01/02 크롤링 결과물인데,\n",
    "# 여기서는 샘플 데이터로 준비\n",
    "headlines = [\n",
    "    {\"title\": \"기사 제목 1\", \"link\": \"https://example.com/1\"},\n",
    "    {\"title\": \"기사 제목 2\", \"link\": \"https://example.com/2\"},\n",
    "    {\"title\": \"기사 제목 3\", \"link\": \"https://example.com/3\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0e5a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ news_headlines.csv 저장 완료\n",
      "     title                   link\n",
      "0  기사 제목 1  https://example.com/1\n",
      "1  기사 제목 2  https://example.com/2\n",
      "2  기사 제목 3  https://example.com/3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 저장\n",
    "df = pd.DataFrame(headlines)\n",
    "df.to_csv(\"news_headlines.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ news_headlines.csv 저장 완료\")\n",
    "\n",
    "# CSV 불러오기\n",
    "df_csv = pd.read_csv(\"news_headlines.csv\")\n",
    "print(df_csv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaca5a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ news_headlines.json 저장 완료\n",
      "     title                   link\n",
      "0  기사 제목 1  https://example.com/1\n",
      "1  기사 제목 2  https://example.com/2\n",
      "2  기사 제목 3  https://example.com/3\n"
     ]
    }
   ],
   "source": [
    "# JSON 저장\n",
    "df.to_json(\"news_headlines.json\", orient=\"records\", force_ascii=False, indent=2)\n",
    "print(\"✅ news_headlines.json 저장 완료\")\n",
    "\n",
    "# JSON 불러오기\n",
    "df_json = pd.read_json(\"news_headlines.json\")\n",
    "print(df_json.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40865d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ news_headlines.xlsx 저장 완료\n",
      "     title                   link\n",
      "0  기사 제목 1  https://example.com/1\n",
      "1  기사 제목 2  https://example.com/2\n",
      "2  기사 제목 3  https://example.com/3\n"
     ]
    }
   ],
   "source": [
    "# Excel 저장\n",
    "df.to_excel(\"news_headlines.xlsx\", index=False, engine=\"openpyxl\")\n",
    "print(\"✅ news_headlines.xlsx 저장 완료\")\n",
    "\n",
    "# Excel 불러오기\n",
    "df_excel = pd.read_excel(\"news_headlines.xlsx\", engine=\"openpyxl\")\n",
    "print(df_excel.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711780c",
   "metadata": {},
   "source": [
    "## 🔑 정리\n",
    "- 크롤링 데이터는 보통 CSV, JSON, Excel 형태로 저장한다.\n",
    "- `pandas.DataFrame`을 사용하면 변환과 저장이 간단하다.\n",
    "- 저장 메서드\n",
    "  - `.to_csv()` : 텍스트 기반, 가장 많이 사용됨\n",
    "  - `.to_json()` : API/웹 서비스와 호환성 좋음\n",
    "  - `.to_excel()` : 오피스 환경에서 바로 활용 가능\n",
    "- 불러오기 메서드\n",
    "  - `read_csv`, `read_json`, `read_excel`\n",
    "- 이렇게 저장해두면 이후 데이터 분석/머신러닝/딥러닝 모델 학습에 재사용 가능하다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_dl (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
